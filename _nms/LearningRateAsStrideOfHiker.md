---
title: Learning Rate as Stride of a Hiker
author: maria
Definition: The learning rate is arguably the most important hyperparameter in training neural networks. It determines the size of the steps the optimization algorithm takes when adjusting the weights of the model in response to the gradients.
Description: "The learning rate is like the stride of a hiker climbing a mountain with a map (the gradient) to reach the summit (optimal model weights). The metaphor highlights that if the stride is too large, the hiker might overshoot or trip, and if it's too small, progress is slow and may never reach the summit efficientlyâ€”just as in training with too high or low a learning rate."
OriginSource: "ChatGPT 4o"
Mapping:
  "Learning rate": "The stride length of the hiker"
  "Optimization algorithm": "The hiker"
  "Adjusting weights": "Climbing or stepping toward the summit"
  "Gradients": "The map or compass that points the hiker in the right direction"
  "Model": "The hiker's route"
  "Optimal model weights": "The summit (goal of the hike)"
  "Training": "The hiking journey"
ExpertRating: Good
---